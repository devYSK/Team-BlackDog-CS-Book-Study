# 3.2 메모리



메모리 : 주 기억장치(주로 데이터를 저장하는 공간)

랜덤 액세스 메모리(RAM)는 시스템의 단기 데이터 스토리지로, 정보에 빠르게 액세스할 수 있도록 컴퓨터가 실시간으로 사용하는 정보를 저장

### 메모리 계층

<img src="https://user-images.githubusercontent.com/41531594/205482431-5d6271cb-24fe-4594-b77e-c4105f23039f.png" width = 700 >

* 레지스터 : CPU 안에 있는 작은 메모리로, 휘발성이이며 속도가 가장 빠르다 - 용량이 가장 적다
* 캐시 : CPU 내부에 있는 메모리로,  L1, L2, L3캐시이다. 레지스터보다 느리며, 레지스터 다음으로는 가장 빠르다. 휘발성이며 용량이 적다. 
* 주 기억장치 : RAM(Random Access Memory) : 휘발성, 속도는 디스크와 레지스터의 중간정도이며(느린편은 아니다) 용량도 비교적 보통인편이다
  * 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장하고 이를 필요시마다 CPU에 빠르게 전달하는 역할
* 보조기억장치:  (하드디스크HDD, SSD-Solid State Disk) 비휘발성이며 속도는 상대적으로 느리고  용량이 많다. 



메모리 계층구조는 다음과같은 특징이 있다.

* 계층 위로 올라갈수록, CPU에 물리적으로 가까워 질수록 속도가 빠르고 물리적으로 멀어질수록 속도가 느리다
* 계층 위로 올라갈수록 용량이 적다.



### 캐시

캐시 : 데이터를 미리 복사해놓는 임시 저장소이자 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리

* ` **CPU와 RAM 사이에서 발생하는 병목 현상을 완화**하고자 사용`

* 캐시는 저장 공간이 작고 비용이 비싼 대신 빠른 성능을 제공한다. 

메모리와 CPU 사이의 속도 차가 너무 크기 때문에 중간에 레지스터 계층을 둬서 속도 차이를 해결한다.

* 캐시 메모리는 CPU 사이에 존재하며 캐시 메모리에 데이터가 존재한다면 메모리에 접근할 필요가 없으므로 성능상 이점을 얻을 수 있다.

* 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층을 캐싱 계층이라고 한다.

Cache는 아래와 같은 경우에 사용을 고려하면 좋다.

- 접근 시간에 비히 원래 데이터를 접근하는 시간이 오래 걸리는 경우(서버의 균일한 API 데이터)
- 반복적으로 동일한 결과를 돌려주는 경우(이미지나 썸네일 등)

> 결국 Cache란 반복적으로 데이터를 불러오는 경우에, 지속적으로 DBMS 혹은 서버에 요청하는 것이 아니라 Memory에 데이터를 저장하였다가 불러다 쓰는 것을 의미



* 원하는 데이터가 캐시에 존재할 경우 해당 데이터를 반환하며, 이러한 상황을 Cache Hit라고 한다.   

* 원하는 데이터가 캐시에 존재하지 않을 경우 메모리나 DBMS 또는 서버에 요청을 해야하며 이를 Cache Miss라고 한다. 



캐시가 효율적으로 동작하기 위해서는 캐시에 저장할 데이터가 지역성(locality)을 가져야한다.



#### 지역성의 원리

지역성이란 코드나 데이터 등이 짧은시간내에 재사용되는 프로그램의 특성  


지역성은 시간 지역성(temporal locality)과 공간 지역성(spatial locality)로 나뉜다.   




#### 시간 지역성

최근에 사용한 데이터에 다시 접근하려는 특성.    


데이터의 읽기/쓰기를 위해 특정 메모리가 사용됐을 때 가까운 시일 내에 해당 메모리가 다시 사용될 가능성이 높은 걸 말한다.  


* ex) for문 . 최근에 사용한 반복 변수 i같은 변수에 계속 접근해서 사용한다.

  


#### 공간 지역성

최근에 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성.  
메모리 주소에 접근할 때 그 주소뿐만 아니라 해당 블록을 전부 캐시에 가져옴으로써 공간 지역성의 효율을 높인다.



* ex)  for문 사용시 배열. 배열에 연속적으로 접근한다.



### 캐시 매핑 (캐시 사상 기법, 캐시 접근 기법)

캐시가 히트되기 위해 매핑하는 방법. 

* **CPU가 필요로 하는 데이터가 캐시내에 있는지 어떻게 알 수 있을까? 그리고 알 수 있다면 어떻게 찾을 수 있을까?** 

* 소용량의 캐시메모리와 상대적 대용량의 중앙메모리 간 효율적인 매핑을 통해 캐시 적중률(Hit Ratio)를 높이기 위한 메커니즘



캐시매핑기법은 3가지가 있다

1. 직접 매핑
2. 연관 매핑
3. 집합 연관 매핑 



## 직접 매핑(Direct Mapping)

\- 메인 메모리를 일정한 블록으로 나누고 각 블록을 캐시 메모리의 특정위치와 매핑하는 방식

\- 특정 블록 내 데이터가 집중적으로 읽혀질 경우 캐시 실패(fault)가 자주 발생되는 단점



![img](https://blog.kakaocdn.net/dn/qEvzm/btqXHhrlvXF/6d50dvUfxoFIQS7DPsVju1/img.png)



![img](https://blog.kakaocdn.net/dn/sgqLL/btqXRvabxs6/kKzalk9ZrATAcBAhRhGaG1/img.png)

출처: http://blog.skby.net/%EC%BA%90%EC%8B%9C-%EC%82%AC%EC%83%81mapping-%EA%B8%B0%EB%B2%95/



우선 메인 메모리에서 캐시로 데이터를 저장할 때 참조의 지역성 때문에 한번 퍼낼 때 인접한 곳까지 한꺼번에 캐시 메모리에 저장하고 이 때 단위를 블록(Block)이라고 한다.  

**그리고 캐쉬는 메인 메모리의 몇번째 블록인지를 알려주는** **태그(Tag)**도 함께 저장한다.  

**메모리 주소 중에 가장 뒷부분(붉은색)은 블럭의 크기**를 의미한다.  



**직접 매핑은 위의 사진처럼 캐시에 저장된 데이터들은 메인 메모리에서와 동일한 배열을 가지도록 매핑하는 방법을 말한다.**   

**이와 같은 방식을 사용하기 때문에 매우 단순하고 탐색이 쉽다는 장점이 있다.**  

**하지만 적중률(Hit ratio)가 낮다는 단점이 있다.**

  




## 연관 매핑(Associative Mapping)

\- 메인 메모리의 내용이 캐시 메모리의 어느 위치에나 매핑이 가능한 사상 기법

\- 캐시 메모리 내 데이터 검색 시 전체 메모리를 스캔해야 하는 제약으로 인해 고가의 메모리 사용 필요 -> 집합연관사상으로 발전



![img](https://blog.kakaocdn.net/dn/sWlH1/btqXLeN49Ui/dM5kpYKazKHv5CWvk9mQi1/img.png)

![img](https://blog.kakaocdn.net/dn/bD7Rst/btqXRvnIFf7/APSDeKPlG3pKH6Itll0JZk/img.png)

출처: http://blog.skby.net/%EC%BA%90%EC%8B%9C-%EC%82%AC%EC%83%81mapping-%EA%B8%B0%EB%B2%95/



연관 매핑은 직접 매핑의 단점을 보완하기 위해 등장하였다.

* **캐시에 저장된 데이터들은 메인 메모리의 순서와는 아무런 관련이 없다.**

이런 같은 방식을 사용하기 때문에 캐시를 전부 뒤져서 태그가 같은 데이터가 있는지 확인해야한다. 따라서 병렬 검사를 위해 **복잡한 회로를 가지고 있는 단점(시간이 오래걸림)**이 있지만 **적중률이 높다**는 장점이 있다.  


**연관매핑이 가장 빠르고 다음 집합 연관 매핑이 빠르며 직접 매핑이 가장 느리다.**



  


## 집합 연관 매핑(Set Association Mapping)

\- 캐시 메모리를 세트로 구성하고, 메인 메모리가 세트에 대응되어 세트 내 자유롭게 매핑이 가능한 캐시 사상 기법



![img](https://blog.kakaocdn.net/dn/SC3Ia/btqXHf74wbY/onIFpbpubsfg6VeySqFFe0/img.png)

출처: http://blog.skby.net/%EC%BA%90%EC%8B%9C-%EC%82%AC%EC%83%81mapping-%EA%B8%B0%EB%B2%95/



### 웹 브라우저의 캐시

웹 브라우저의 쿠키, 로컬 스토리지, 세션 스토리지가 있다.

* 보통 사용자의 커스텀 정보나 인증 모듈 관련 사항들을 웹 브라우저에 저장해서 추후 서버에 요청할 때 Id나 중복 요청 방지를 위해 쓰인다



### 쿠키, 웹 스토리지(로컬 스토리지, 세션 스토리지) 생성 배경

> - HTTP는 요청과 응답으로 이뤄지는 하나의 사이클이 끝나면, 연결이 끊어지는 무상태성을 띄어서 클라이언트의 상태를 보존하지 않는다
> - 클라이언트의 상태를 서버가 아닌 클라이언트에 저장해두고 필요시마다 데이터를 꺼내서 서버에 전달하는 방식으로 HTTP의 단점을 보완하고자 쿠키와 웹 스토리지를 사용한다



### 쿠키

- 만료 기간이 있는 클라이언트 단에 저장하는 키-값 저장소 역할을 하는 작은 텍스트 파일
- 요청과 응답만이 존재했던 HTTP 웹세계에 이전에 서버와 클라이언트가 주고 받은 내역을 기억하고 불러올 수 있는 혁신적인 역할을 수행

- document.cookie하면 현재 쿠키 정보가 나옴.
- 사용자 인증이 유효한 시간을 명시할 수 있으며, 유효 시간이 정해지면 브라우저가 종료되어도 인증이 유지됨.
- 쿠키는 클라이언트의 상태 정보를 로컬에 저장했다가 .
- 클라이언트에 300개까지 쿠키저장 가능, 하나의 도메인당 20개의 값만 가질 수 있음, 하나의 쿠키값은 4KB까지 저장.
- Response Header에 Set-Cookie 속성을 사용하면 클라이언트에 쿠키를 만들 수 있다.
- 쿠키는 사용자가 따로 요청하지 않아도 브라우저가 Request시에 Request Header를 넣어서 자동으로 서버에 전송

* 클라이언트 또는 서버에서 만료기한 등을 정할 수 있는데 보통 서버에서 만료기한을 정한다



### 쿠키 종류

> - Session Cookie: 메모리에만 저장되며, 만료시간이 있지만 브라우저 종료시 삭제되는 쿠키
> - Persistent Cookie: 파일로 저장되며, Max-Age 설정을 통해 장기간 유지 가능하고 브라우저 종료와 관계없이 사용 가능한 쿠키
> - Secure Cookie: HTTPS에서 사용되는 암호화된 쿠키. 비교적 안전하지만 실질적 보안이 제공되지 않아 민감한 데이터 저장 절대 금지
> - Third Party Cookie: 다른 도메인에 요청이 필요할 때 생성하는 쿠키. 주로 광고 목적으로 사용되며, 유저 개인정보 악용의 문제 발생



### 쿠키 동작 원리

> - 클라이언트가 서버에 HTTP 요청
> - 서버가 HTTP 응답시 set-cookie를 통해 쿠키 생성하여 전달
> - 클라이언트는 이제부터 매 HTTP Request시 HTTP Header에 쿠키담아서 전송
> - 만료 기간 전이라면, 쿠키는 브라우저에 저장되어 있으며, 항상 요청시 사용 가능
> - 만료됬다면, 클라이언트가 새로 서버에 요청하여 쿠키 새로 발급



### 쿠키 특징

#### 장점

> - 대부분의 브라우저가 지원
> - 데이터 유효기간 지정 가능 (ex. 1 hour, 1 day)
> - XSS (사이트 간 악성 Js 코드를 심는 행위)로부터 안전 - 서버에서 쿠키의 httpOnly 옵션을 설정하면, Js에서 쿠키에 접근 자체가 불가능



#### 단점

> - 매우 작은 데이터 저장 용량 (4kb)
> - 매번 서버에 HTTP 요청시 같이 전달되어 서버에 부담
> - 암호화가 안되어 있어 유저 정보 도난 위험
> - CSRF(사이트 간 요청 위조) 위협 - 공격자가 사용자의 요청을 가로챈 뒤 사용자의 의지와 상관없이 보안적으로 위험한 행동을 하게끔 변조하여 부당 이익을 취하는 행위
> - 문자열만 저장 가능



### 로컬 스토리지와 세션스토리지

로컬 스토리지와 세션 스토리지는 HTML5에서 추가된 저장소. HTML5를 지원하지 않는 브라우저에서는 사용할 수 없다. 

* 키-값 스토리지의 형태로 간단한 키와 값을 저장할 수 있다 .
* 클라이언트에서만 수정할 수 있다.

|             | 로컬 스토리지                           | 세션 스토리지                   |
| ----------- | --------------------------------------- | ------------------------------- |
| 데이터 영구 | O (사용자가 지우지 않는 한)             | X (윈도우, 탭 닫을시 내용 제거) |
| 사용방법    | 자동 로그인                             | 일회성 로그인                   |
| 주의사항    | 비밀번호와 같은 중요 정보는 절대 저장 X |                                 |



### 로컬 스토리지와 세션 스토리지 차이점

> - 로컬 스토리지는 데이터 영구 저장이 가능, 세션 스토리지는 브라우저 탭/윈도우가 닫히면 스토리지가 초기화
> - 로컬 스토리지는 window.localStorage, 세션 스토리지는 window.sessionStorage 객체 사용



### 쿠키, 로컬 스토리지, 세션 스토리지 사용처

* **쿠키** : 일시적으로 필요한 가벼운 데이터 저장이 필요할 때
  - 다시 보지 않음 쿠키 팝업창 , 로그인 자동 완성

- **로컬 스토리지** : 지속적으로 필요한 데이터 저장이 필요할 때
  - 자동 로그인
- **세션 스토리지** : 일시적으로 필요한 데이터 저장이 필요할 때
  - 일회성 로그인, 입력 폼 저장, 비로그인 장바구니



### 데이터베이스의 캐싱 계층

데이터베이스 시스템을 구축할 때도 메인 데이터베이스 위에 redis 라는 데이터 베이스 계층을 캐싱 계층으로 둬서 성능을 향상 시킬 수 있다.





---

## 메모리 관리



운영체제는 컴퓨터 내의 한정된 메모리를 극한으로 활용하기 위해 메모리를 관리해준다.



## 가상메모리(Virtual memory)

메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것

> 가상 메모리는 메모리가 실제 메모리보다 많아 보이게 하는 기술로, 어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하다는 점에 착안하여 고안되었다.



### 2. 가상 메모리 등장 배경

- 초창기 컴퓨터에서는 사용 가능한 RAM의 용량이, 가장 큰 실행 애플리케이션의 주소 공간보다 커야 했다. 
  - 그렇지 않을 경우 "메모리 부족" 오류에 의해 해당 애플리케이션을 실행할 수 없기 때문에.
- 이후 컴퓨터에서는 프로그래머가 애플리케이션의 일부분만 기억장치에 올려 실행하도록 지정할 수 있게 하는 **오버레이 기법**을 사용하여 메모리 부족 문제를 해결하고자 했다. 
  - 하지만 이 역시 전반적인 메모리 부족 문제를 해결할 수 없었다. 
  - 오버레이를 사용하는 프로그램은 그렇지 않은 프로그램보다는 메모리를 덜 사용했지만, 애초에 시스템이 프로그램을 위한 충분한 메모리를 갖추고 있지 않은 경우에는 결국 똑같은 메모리 부족 오류가 발생했다.
- 여기에서 더 발전한 **가상 메모리 기법**은 애플리케이션을 실행하는 데 얼마나 많은 메모리가 필요한지에 집중하지 않고, 대신 애플리케이션을 실행하는 데 최소한 얼마만큼의 메모리가 필요한가에 집중하여 문제를 해결하고자 하였따.
  - 이렇게 접근하는 방식이 가능한 이유는, 메모리 접근은 순차적이고 지역화되어 있기 때문이다.
  - 그렇다면 이렇게 애플리케이션의 일부분만 메모리(기억장치)에 올려진다면, 메모리에 올라가지 않는 나머지는 어디에 위치해야 할까? ⇒ **보조 기억장치, 즉 디스크**!
  - `가상 메모리의 핵심은 보조 기억장치다.`



가상 메모리 방식은 [멀티태스킹](https://ko.wikipedia.org/wiki/멀티태스킹) 운영 체제에서 흔히 사용되며, 실제 [주기억장치](https://ko.wikipedia.org/wiki/주기억장치)보다 큰 메모리 영역을 제공하는 방법으로도 사용된다.

* 가상적으로 주어진 주소를 [가상 주소](https://ko.wikipedia.org/wiki/가상_주소)(virtual address) 또는 논리 주소(logical address) 라고 한다.
* 실제 메모리 상에서 유효한 주소를 [물리 주소](https://ko.wikipedia.org/wiki/물리_주소)(physical address) 또는 실주소(real address)라고 한다. 
* 가상 주소의 범위를 가상 주소 공간, 물리 주소의 범위를 물리 주소 공간이라고 한다.

가상 주소 공간은 [메모리 관리 장치](https://ko.wikipedia.org/wiki/메모리_관리_장치)(MMU)에 의해서 물리 주소로 변환된다. 이 덕분에 프로그래머는 가상 주소 공간상에서 프로그램을 짜게 되어 프로그램이나 데이터가 주메모리상에 어떻게 존재하는지를 의식할 필요가 없어진다. 



#### 가상 메모리의 주요한 기능 

*  주기억장치의 효율적 관리(스와핑): 하드디스크를 주기억장치에 대한 캐시로 설정하여, 당장 사용하는 영역만 유지하고 쓰지 않는 데이터는 하드디스크로 옮긴 뒤, 필요할 때만 램에 데이터를 불러와 올리고 다시 사용하지 않으면 하드디스크로 내림으로써 램을 효과적으로 관리한다. 
*  메모리 관리의 단순화: 각 프로세스마다 가상메모리의 통일된 주소 공간을 배정할 수 있으므로 메모리 관리가 단순해진다. 
*  메모리 용량 및 안정성 보장: 한정된 공간의 램이 아닌 거의 무한한 가상메모리 공간을 배정함으로써 프로세스들끼리 메모리 침범이 일어날 여지를 크게 줄인다



#### MMU(Memory Management Unit)

- 가상 메모리를 구현하기 위해서는 컴퓨터가 특수 메모리 관리 하드웨어를 갖추고 있어야만 한다. 
- [**MMU(Memory Management Unit)**](https://ko.wikipedia.org/wiki/메모리_관리_장치)
  - MMU는 가상주소를 물리주소로 변환하고, 메모리를 보호하는 기능을 수행한다
  - MMU를 사용하게 되면, CPU가 각 메모리에 접근하기 이전에 메모리 주소 번역 작업이 수행된다.
  - 그러나 메모리를 일일이 가상 주소에서 물리적 주소로 번역하게 되면 작업 부하가 너무 높아지므로, MMU는 RAM을 여러 부분(페이지, pages)로 나누어 각 페이지를 하나의 독립된 항목으로 처리한다.
  - 페이지 및 주소 번역 정보를 기억하는 작업이 가상 메모리를 구현하는 데 있어 결정적인 절차이다.



가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고, 프로세스의 주소 정보가 들어이는 페이지 테이블로 관리된다. 이 때 속도 향상을 위해 TLB를 사용한다

* TLB: Translation Lookaside Buffers
  * 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시.
  * 페이지 테이블에 있는 리스트를 보관하여 CPU가 페이지 테이블까지 가지 않도록 해속도를 향상시킬 수 있는 캐시 계층



### 페이지 테이블(Page Table) 이란?

페이지 테이블은 논리주소의 페이지를 물리주소의 프레임으로 매핑시켜주는 정보를 담고 있는 테이블이다. 

  


#### 프레임과 페이지

프레임과 페이지는 메모리를 일정한 크기의 공간으로 나누어 관리하는 단위이며, 프레임과 페이지의 크기는 같다.

- 프레임(Frame) : 물리 메모리를 일정한 크기로 나눈 블록이다. - 가상 메모리를 사용하는 최소 크기 단위
- 페이지(Page) : 가상 메모리를 일정한 크기로 나눈 블록이다. - 실제 메모리를 사용하느 ㄴ최소 크기 단위

페이지가 하나의 프레임을 할당 받으면, 물리 메모리에 위치하게 된다. 프레임을 할당 받지 못한 페이지들은 [외부 저장장치](https://ko.wikipedia.org/w/index.php?title=외부_저장장치&action=edit&redlink=1)에 저장되며, 이때도 프레임과 같은 크기 단위로 관리된다.



### 스와핑(**swapping**)

* swap이란 단어는 두 개의 값을 맞바꾼다, 교환한다 의 의미를 가지고 있다



만약 가상 메모리에는 존재하지만, 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트가 발생한다.

* 페이지 폴트 : **페이지 부재** 또는 **페이지 폴트**는 메모리에 적재된 페이지중에 사용 페이지가 없을 때를 가리킨다. 
  * 프로세스의 주소공간에는 존재하지만 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우에 발생
  * 즉, 물리 메모리에 CPU가 요청한 페이지가 없을 때 발생한다.

페이지 폴트가 발생했을 때 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는것을 스와핑이라 한다.   


페이지 폴트로 인한 스와핑은 다음과 같은 같은 과정으로 이루어 진다.

1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩(인터럽트)을 발생시켜 운영체제에 알린다.
2. 운영체제는 CPU의 동작을 잠깐 멈춘다(인터럽트).
3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어있는 프레임이 있는지 찾는다. 물리 메모리에도 없다면 스와핑이 발생한다.
4. 비어있는 프레임에 해당 페이지를 로드하고 페이지 테이블을 최신화한다.(스와핑)
5. 중단되었떤 CPU를 다시 시작한다.



### 스레싱(thrashing)

 **메모리 영역에 접근하게 될 때, 메모리에 페이지 부재(=페이지 폴트(Page fault)율이 높은 것**을 의미하며, 심각한 성능 저하를 초래한다.

과도한 페이징 작업을 Thrasing(스레싱) 이라 하는데, 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생하는 것이다.  

* 페이지 폴트가 일어나면 CPU 이용률이 낮아진다.
  * 스와핑이 일어나는데, 메모리에서 페이지를 읽어오는 시간만큼 운영체제가 멈추니까 낮아진다.
* CPU 이용률이 낮아지게 되면 OS는 가용성을 높이기 위해 더 많은 프로세스를 메모리에 올리게 된다.
  * 여러 프로세스들은 각자의 페이지와 프레임을 필요로 하는데 현재 폴트이므로 페이지를 교체한다.
  * 교체된 페이지들이 어떤 프로세스에서 필요로 하는 것이었는데, 다른 프로세스가 페이지를 필요로 하므로 스와핑을 하니까 아무도 페이지를 이용하지 못하고 역시 페이지 폴트를 발생시키고 또 다른 프로세스에서 스와핑이 발생하기 때문이다.



이를 해결하기 위한 방법으로는 메모리를 늘리거나 SSD로 교체하는 방법이 있다.    

* 운영체제에서의 해결방법은 작업 세트와 PFF가 있다.  
* 각 프로세스가 필요로 하는 최소한의 프레임 갯수를 보장

### 작업 세트 (working set)

프로세스의 과거 사용 이력인 지역성을 통해 결젱된 페이지 집합을 만들어서 미리 메모리에 로드하는 것.

* 미리 메모리에 로드하면 탐색에 드는 비용을 줄일 수 있고 스와핑 또한 줄일 수 있다.

### PFF (Page Fault Frequency)

페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법

* 상한선에 도달한다면 프레임을 늘리고 하한선에 도달한다면 프레임을 줄인다.



## 메모리 할당

메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당하는데 연속 할당과 불연속 할당으로 나눈다



### 연속 할당

메모리에 연속적으로 공간을 할당하는 방식.

이는 메모리를 미리 나누어 관리하는 고정 분할 방식과 매 시점 프로그램 크기에 맞게 메모리를 분할하여 사용하는 가변 분할 방식이 있다.



#### 고정 분할 방식(fixed partition allocation)

메모리를 미리 나누어 관리하는 방식. 메모리가 미리 나뉘어 있끼 때문에 융통성이 없다. 

* 내부 단편화가 발생한다.



#### 가변 분할 방식(variable partition allocation)

매 시점 프로그램의 크기에 맞게 동적으로 메모리를 사용

* 내부 단편화는 발생하지 않고 외부 단편화는 발생할 수 있다.
* 최초 적합, 최적 적합, 최악 적합이 존재
  * 최초 적합 : 위쪽이나 아래쪽부터 시작해서 맞는곳이 있으면 바로 할당
  * 프로세스의 크기 이상인 공간 중 가장 작은 곳부터 할당
  * 프로세스의 크기와 가장 많이 차이가 나는 곳에 할당



#### 내부 단편화 외부 단편화

* 내부 단편화 : 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
* 외부 단편화 : 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상



### 불연속 할당

메모리를 연속적으로 할당하지 않는 불연속 할당은 현대 운영체제가 쓰는 방법이며 페이징 기법, 세그멘테이션, 페이지드 세그멘테이션 기법이 있다.

* 페이징 기법 : 메모리를 동일한 크기의 페이지(보통4kb)로 나누고 프로그램마다 페이지 테이블을 두어 이를 통해 메모리에 프로그램을 할당
* 세그멘테이션 : 페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식
  * 프로세스는 코드, 데이터, 스택, 힙 등으로 나누어 지는데 특정 단위로 나눌 수도 있음을 의미.
  * 공유와 보안측면에선 좋지만 홀 크기(비어있는 메모리공간)가 균일하지 않은 문제가 발생한다.
* 페이지드 세그멘테이션 : 공유나 보안을 의미 단위의 세그먼트로 나누고 물리적 메모리는 페이지로 나누는 것을 말한다.



## 페이지 교체 알고리즘

메모리는 한정되어 있기 때문에 스와핑이 많이 일어난다. 

이 대 페이지 교체 알고리즘을 기반으로 스와핑이 일어난다.



### 오프라인 알고리즘(offline algorithm)

먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘이며 가장 좋은 방법이다.

* 그러나 미래에 사용되는 프로세스를 알 수 없기 때문에 사용할 수 없는 알고리즘이지만 다른 알고리즘과의 성능 비교에 대한 기준을 제공한다.



### FIFO(First In First Out)

가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법

- 구현이 간단하지만 성능은 좋지 않은 편이다.
- 들어온 시간을 저장하거나 올라온 순서를 큐를 이용해 저장할 수 있다.



###  LRU(Least Recentle Used)

참조가 가장 오래된 페이지를 교체 .

* 오래된 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야 한다 

- 최적 알고리즘과 비슷한 효과를 낼 수 있다.

- 성능이 좋은 편이다.

- 많은 운영체제가 채택하는 알고리즘이다.

  


LRU을 구현할 때는 보통 두 개의 자료구조로 구현한다.  

* 해시 테이블과 이중 연결 리스트
* 해시 테이블은 이중 연결 리스트에서 빠르게 찾을 수 있또록 쓰고, 이중 연결리스트는 한정된 메모리를 나타낸다.



### NUR(Not Used Recently)

최근에 사용하지 않은 페이지 교체 (LRU를 근사한 알고리즘)

* clock 알고리즘이라고도 불린다. 

- 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 못함
- 적은 오버헤드로 적절한 성능
- 동일 그룹 내에서 선택 무작위
- 각 페이지마다 두개의 비트 참조 비트(Reference Bit)와변형 비트(Modified Bit, Birty Bit) 가 사용됨
  - 참조 비트: 페이지가 참조되지 않았을 때 0, 호출되었을 때 1 (모든 참조비트를 주기적으로 0으로 변경)
  - 변형 비트: 페이지 내용이 변경되지 않았을 때는 0, 변경되었을 때 1
- 우선순위: 참조비트 > 변형비트
- 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고 1로 바꾸는 알고리즘



### LFU(Least Frequently Used)

참조 횟수가 가장 낮은 페이지를 교체 -    많이 사용되지 않은 페이지를 교체

- 페이지의 참조 횟수로 교체할 페이지 결정
- LRU는 직전 참조된 시점만을 반영하지만, LFU는 참조횟수를 통해 장기적 시간규모에서의 참조성향 고려할 수 있음
- 단점: 가장 최근에 불러온 페이지가 교체될 수 있음, 구현 더 복잡, 막대한 오버헤드