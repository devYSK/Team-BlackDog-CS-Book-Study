# 메모리

## 메모리 계층
![image](https://user-images.githubusercontent.com/53592454/208400133-0b96916c-0d86-4521-879e-8240a8bbc508.png)


## 캐싱 ***Caching***

캐시는 굉장히 빠르고 작은 저장장치이며, 캐싱은 **캐시 메모리를 사용해 컴퓨터의 속도를 높이는 기술**이다. 데이터를 디스크에서 직접 가져오는 것은 너무 느리기 때문에 캐시에 자주 사용될 것 같은 데이터를 미리 담아두고, CPU나 디스크가 캐시의 데이터를 참조할 수 있도록 한다. 

**파일의 중복성이 증가하지만, 속도 역시 증가한다.** 캐싱은 **지역성**(Locality) 원리를 사용한다. 지역성은 시간지역성(Temporal locality)과 공간지역성(Spatial Locality)으로 나뉜다. 

**시간지역성**은 한 번 접근한 데이터에 다시 접근할 확률이 높다는 것이다. 공간지역성은 특정 데이터와 가까운 메모리 주소에 있는 다른 데이터들에도 접근할 가능성이 높다는 것이다.

```java
for (int i = 0; i < 10; i++) { ... }
```

**공간지역성**은 특정 데이터와 가까운 메모리 주소에 있는 다른 데이터들에도 접근할 가능성이 높다는 것이다. 

```java
for (int i = 0; i < 10; i++) {
  arr[i] += 1;
}

```

배열 변수 `arr`의 0번 요소부터 순서대로 9번 요소까지 접근한다. 메모리 공간에 배열의 요소들은 그 순서대로 붙어 할당되니까 실제로 가까운 메모리 공간에 연속적으로 접근하고 있다. 캐시는 한 메모리 주소에 접근했을 때 그 주변의 메모리 주소도 함께 가져온다.

캐시미스를 줄이고, **캐시히트**를 높이기 위해 캐싱할 데이터를 잘 매핑하는 것이 중요하다. 

### 캐시히트와 캐시미스

캐시에서 원하는 데이터를 찾으면 **캐시히트**, 캐시에서 원하는 데이터를 찾지 못하면 메모리에 가서 데이터를 찾아오면 **캐시미스**이다.

![image](https://user-images.githubusercontent.com/53592454/208400235-82255b86-f9cb-4e8a-b205-3b68d12c3e74.png)

### 캐시매핑

- 직접매핑 : 순서가 중요. 메인메모리와 캐시를 똑같은 크기로 나누고 순서대로 매핑. 1~100까지 있고 캐시가 1~10까지 있다면 1~10까지의 메모리는 캐시의 1에 위치하고 11~20까지의 메모리는 캐시의 2에 위치. 캐시히트 낮음
- 연관매핑 : 순서안중요. 관련있는 캐시와 메모리 매핑. 모든블록을 탐색해 속도가 느림. 캐시히트 높음.
- 집합연관매핑 : 직접매핑 + 연관매핑. 순서는 일치시키지만, 집합을 두어 연관. 메모리가 1~100까지 있고 캐시가 1~10까지 있다면 캐시 1~5에는 1~50의 데이터를 무작위로 저장

### 용례 1 : 웹 브라우저의 캐시

- 쿠키, 로컬 스토리지, 세션 스토리지

| 쿠키 | 최대용량이 4KB이고, 만료기한이 있는 키-값 형태의 저장소. 보통 서버에서 만료기한을 정한다. 쿠키 설정 시에는 document.cookie를 통해 쿠키를 볼 수 없도록 httponly 옵션을 거는 것이 중요! |
| --- | --- |
| 로컬 스토리지 | 최대용량이 10MB이고, 만료기한이 없는 키-값 형태의 저장소. 웹 브라우저를 닫아도 유지되며, 도메인 단위로 저장된다. HTML5를 지원하는 웹 브라우저에서 사용 가능하며, 클라이언트에서 수정할 수 있다. |
| 세션 스토리지 | 최대용량이 5MB이고, 만료기한이 없는 키-값 형태의 저장소. 웹 브라우저를 닫으면 삭제 된다. HTML5를 지원하는 웹 브라우저에서 사용 가능하며, 클라이언트에서 수정할 수 있다. |

### 용례 2 : 데이터베이스의 캐싱 계층

메인 데이터베이스 위에 Redis 데이터베이스 계층을 캐싱 계층으로 둬서 성능 향상시킴.

## 메모리 관리

### ****Address Binding : Logical Address vs Physical Address****

- 논리적 주소는 가상 주소(Virtual address)라고도 하며, CPU가 생성하는 주소이다. 프로세스마다 독립적으로 가지는 주소 공간이기 때문에 프로세스의 내부에서 사용하고, 각 프로세스마다 0부터 시작한다.
- 물리적 주소는 프로세스가 실행되기 위해 실제로 메모리(RAM)에 올라가는 위치이다.
- Address Binding 시점은 Compile Time, Load Time, Run Time으로 분류된다.

### 가상메모리

메모리 관리 기법 중 하나로, 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화해 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것이다. 가상메모리는 가상주소와 실제 주소가 매핑되어 있고, 프로세스의 주소 정보가 있는 페이지 테이블로 관리된다. 이때 속도 향상을 위해 TLB를 사용한다.

> **TLB**
메모리와 CPU 사이에 있는 주소 변환을 위한 캐시
> 

![image](https://user-images.githubusercontent.com/53592454/208400407-ef270840-4e6e-4999-a356-d14ceb5b3275.png)
### 스와핑

메모리는 크기가 크지 않기 때문에 프로세스를 임시로 디스크에 보냈다가 다시 메모리에 로드해야 하는 상황이 생긴다. 이때 디스크로 내보내는 것을 swap out, 메모리로 들여보내는 것을 swap in이라고 한다. swapping을 통해 하드디스크의 일부를 메모리처럼 사용한다.

### 페이지폴트 Page Fault

프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우에 발생하는 형상이다. 그 결과 스와핑 과정이 동반된다. 

### 스레싱

메모리의 페이지 폴트율이 높은 현상을 의미한다. CPU 이용률이 낮아져 운영체제가 더 많은 프로세스를 메모리에 올리며 컴퓨터의 심각한 성능 저하를 초래한다.

![image](https://user-images.githubusercontent.com/53592454/208400589-3fe766b2-d278-4ac9-b6da-bd380e707d1f.png)

**해결 방법**

1. 메모리 늘리기
2. HDD를 SSD로 바꾸기
3. 작업세트와 PFF 이용하기

> **작업세트**
프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리 로드하는 것이다.
> 

> **PFF** *Page Fault Frequency*
페이지 폴트 빈도를 조절하는 방법으로, 상한선에 도달하면 프레임을 늘리고, 하한선에 도달하면 프레임을 줄인다.
> 

### 메모리 할당

- 연속할당 : 메모리에 연속적으로 공간을 할당하는 것
    - 고정분할방식 : 메모리를 미리 나누어 관리하는 방식, 메모리가 미리 나뉘어있기 때문에 융통성이 없다. 내부 단편화가 발생한다.
    - 가변분할방식 : 매 시점 프로그램의 크기에 따라 동적으로 메모리를 나누어 사용. 내부 단편화는 방생하지 않으나 외부 단편화는 발생가능
        - 최초적합 : 위쪽이나 아래쪽부터 시작해 홀(비어있는 메모리 공간)을 찾으면 바로 할당
        - 최적적합 : 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당
        - 최악적합 : 프로세스의 크기와 가장 많이 차이가 나는 홀에 할당
- 불연속할당 : 메모리에 연속적으로 공간을 할당하지 않는 것.
    - 현대 운영체제가 쓰는 방법으로 **페이징** 기법이 있다. 메모리를 동일한 크기(4KB로) 나누고 프로그램마다 페이지 테이블을 두고, 이 테이블을 통해 메모리에 프로그램을 할당하는 기법이다.
    - 이 외에도 세그멘테이션, 페이지드 세그멘테이션 기법이 있다.

| 페이징 | 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당한다. 홀의 크기가 균일하지 않은 문제가 없지만 주소변환이 복잡해질 수 있다. 내부단편화가 발생할 수 있다. |
| --- | --- |
| 세그멘테이션  | 페이지 단위가 아닌 의미 단위로 나누는 것이다. 코드와 데이터 기반으로 나누거나, 함수 단위로 나눌수도 있다. 공유와 보안 측면에서 좋지만 홀 크기가 균일하지 않아 외부단편화가 발생할 수 있다. |
| 페이지드 세그멘테이션 | 일단 세그멘테이션을 하고, 외부 단편화 문제를 막기 위해 페이징을 사용한다. 두 단계를 거치므로 성능이슈가 있다. |

![image](https://user-images.githubusercontent.com/53592454/208400692-deccce0f-3d35-4088-9009-681663ac8f23.png)

### 페이지교체 알고리즘

메모리는 한정되어 있기 때문에 스와핑이 많이 일어난다. 스와핑을 최대한 방지하는 페이지 교체 알고리즘이 필요하다.

**오프라인 알고리즘**

먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘이다. 이론적으로 가장 좋은 방법이지만 실현 불가능하므로 다른 알고리즘과 성능 비교용으로 사용된다.

**FIFO *First In First Out***

가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법이다.

**LRU *Least Recently Used***

참조가 가장 오래된 페이지를 바꾸는 방법이다. 오래된 정도를 파악하기 위해 각 페이지마다 계수기와 스택을 두어야 하는 문제점이 있다.

**NUR *Not Used Recently***

a.k.a clock 알고리즘. LRU에서 발전된 방법이다. 0과 1을 가진 비트를 두고(1은 최근에 참조되었다는 의미, 2는 참조되지 않았다는 의미) 시계 방항으로 돌면서 0을 찾고 0을 찾은 순간 프로세스를 교체하고 1로 바꾸는 방식이다.

**LFU *Least Frequently Used***

가장 참조 횟수가 적은(가장 덜 사용된) 페이지를 교체한다. 

**Refs.**

[Simultaneous and Hierarchical Cache Accesses - GeeksforGeeks](http://geeksforgeeks.org/simultaneous-and-hierarchical-cache-accesses/)

[https://bellog.tistory.com/159](https://bellog.tistory.com/159)
